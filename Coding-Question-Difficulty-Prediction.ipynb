{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Question Difficulty Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a project with the aim of predicting difficulty in answering competitive coding questions using labelled data from [codeforces.com](http://codeforces.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It classifies problems into three levels of difficulty- Easy, Medium, and Hard from a dataset of around 2000 questions containing - The question text, the input, and the output specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Prabhu\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import keras.utils\n",
    "\n",
    "import nltk\n",
    "import glob\n",
    "import os.path\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lower(string):\n",
    "    return \" \".join(nltk.word_tokenize(string)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    reads all question files and returns - \n",
    "    q_text, input, output, label\n",
    "    '''\n",
    "\n",
    "    complexities = dict()\n",
    "    complexity_file = open(\"questions-complexity.csv\", encoding='utf-8')\n",
    "    complexity_file.readline()\n",
    "\n",
    "    for line in complexity_file:\n",
    "        line = line.strip().split(\",\")\n",
    "        complexities[line[0]] = line[-2]\n",
    "    complexity_file.close()\n",
    "\n",
    "\n",
    "    question_files = sorted(glob.glob(\"./questions/*.txt\"))\n",
    "    questions = []\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    labels = []\n",
    "\n",
    "    for f in question_files:\n",
    "        handle = open(f, encoding='utf-8')\n",
    "        text = handle.read()\n",
    "        handle.close()\n",
    "        text_split = text.split(\"\\n\\n\")\n",
    "        question = text_split[2]\t### + [3] and [4] for Input and Output requirement text\n",
    "        input_text = text_split[3]\n",
    "        output_text = text_split[4]\n",
    "\n",
    "        # Removes 'Input' and 'Output' prefixes\n",
    "        input_text = input_text[len('Input'):]\n",
    "        output_text = output_text[len('Output'):]\n",
    "\n",
    "        question = tokenize_and_lower(question)\n",
    "        input_text = tokenize_and_lower(input_text)\n",
    "        output_text = tokenize_and_lower(output_text)\n",
    "\n",
    "        questions.append(question)\n",
    "        inputs.append(input_text)\n",
    "        outputs.append(output_text)\n",
    "        labels.append(complexities[os.path.basename(f).strip(\".txt\")])\n",
    "\n",
    "    return questions, inputs, outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_word_frequencies(word_freq, text):\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token not in word_freq:\n",
    "            word_freq[token] = 0\n",
    "        else:\n",
    "            word_freq[token] += 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(questions, inputs, outputs):\n",
    "    '''\n",
    "    takes list of questions (returned from load_data) and returns a list of words sorted in desending order of frequency\n",
    "    '''\n",
    "    word_freq = dict()\n",
    "    word_freq['<UNK>'] = 0\n",
    "    \n",
    "    for ques in questions:\n",
    "        populate_word_frequencies(word_freq, ques)\n",
    "            \n",
    "    for input_text in inputs:\n",
    "        populate_word_frequencies(word_freq, input_text)\n",
    "        \n",
    "    for output_text in outputs:\n",
    "        populate_word_frequencies(word_freq, output_text)\n",
    "        \n",
    "    top_words = sorted(word_freq, key = lambda w : word_freq[w], reverse = True)\n",
    "    vocab_size = len(top_words)\n",
    "\n",
    "    return top_words, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_vector(text, vocab):\n",
    "    vector = []\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        try:\n",
    "            vector.append(vocab.index(token))\n",
    "        except:\n",
    "            vector.append(vocab.index('<UNK>'))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_labels(labels):\n",
    "    labels = [0 if l == \"Easy\" else l for l in labels]\n",
    "    labels = [1 if l == \"Medium\" else l for l in labels]\n",
    "    labels = [2 if l == \"Hard\" else l for l in labels]\n",
    "\n",
    "    labels_vector = keras.utils.to_categorical(labels)\n",
    "\n",
    "    return labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(questions, inputs, outputs, vocab):\n",
    "    question_vectors = []\n",
    "    input_vectors = []\n",
    "    output_vectors = []\n",
    "    \n",
    "    for ques in questions:\n",
    "        question_vectors.append(get_frequency_vector(ques, vocab))\n",
    "\n",
    "    for input_text in inputs:\n",
    "        input_vectors.append(get_frequency_vector(input_text, vocab))\n",
    "        \n",
    "    for output_text in outputs:\n",
    "        output_vectors.append(get_frequency_vector(output_text, vocab))\n",
    "        \n",
    "    return question_vectors, input_vectors, output_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, inputs, outputs, labels = load_data()\n",
    "vocab, vocab_size = create_vocab(questions[:1700], inputs[:1700], outputs[:1700])\n",
    "labels = categorize_labels(labels)\n",
    "question_vectors, input_vectors, output_vectors = vectorize_data(questions, inputs, outputs, vocab)\n",
    "\n",
    "question_vectors_train, input_vectors_train, output_vectors_train, labels_train = question_vectors[:1700], input_vectors[:1700], output_vectors[:1700], labels[:1700]\n",
    "question_vectors_test, input_vectors_test, output_vectors_test, labels_test = question_vectors[1700:], input_vectors[1700:], output_vectors[1700:], labels[1700:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7780"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index('<UNK>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_length = 300\n",
    "max_input_length = 50\n",
    "max_output_length = 50\n",
    "embedding_vector_length = 32\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(question_vectors_train, input_vectors_train, output_vectors_train, labels_train, vocab_size, max_question_length, max_input_length, max_output_length, embedding_vector_length, n_epochs):\n",
    "    question_vectors_sequence = sequence.pad_sequences(question_vectors_train, maxlen=max_question_length)\n",
    "    input_vectors_sequence = sequence.pad_sequences(input_vectors_train, maxlen=max_input_length)\n",
    "    output_vectors_sequence = sequence.pad_sequences(output_vectors_train, maxlen=max_output_length)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_vector_length))\n",
    "\n",
    "    model.add(LSTM(10))\n",
    "\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    X = np.concatenate([question_vectors_sequence, input_vectors_sequence, output_vectors_sequence], axis=1)\n",
    "    model.fit(X, labels_train, epochs=n_epochs, batch_size=64, verbose=1)\n",
    "\n",
    "    print('SUMMARY:', model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(question_vectors_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1700/1700 [==============================] - 9s 5ms/step - loss: 1.0950 - acc: 0.3694\n",
      "Epoch 2/5\n",
      "1700/1700 [==============================] - 7s 4ms/step - loss: 1.0814 - acc: 0.4324\n",
      "Epoch 3/5\n",
      "1700/1700 [==============================] - 7s 4ms/step - loss: 1.0492 - acc: 0.4865\n",
      "Epoch 4/5\n",
      "1700/1700 [==============================] - 7s 4ms/step - loss: 0.9821 - acc: 0.5359\n",
      "Epoch 5/5\n",
      "1700/1700 [==============================] - 8s 5ms/step - loss: 0.8768 - acc: 0.6188\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          455936    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10)                1720      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 457,689\n",
      "Trainable params: 457,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "SUMMARY: None\n"
     ]
    }
   ],
   "source": [
    "model = build_model(question_vectors_train, input_vectors_train, output_vectors_train, labels_train, vocab_size, max_question_length, max_input_length, max_output_length, embedding_vector_length, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, question_vectors_test, input_vectors_test, output_vectors_test, labels_test, max_question_length, max_input_length, max_output_length):\n",
    "    question_vectors_sequence = sequence.pad_sequences(question_vectors_test, maxlen=max_question_length)\n",
    "    input_vectors_sequence = sequence.pad_sequences(input_vectors_test, maxlen=max_input_length)\n",
    "    output_vectors_sequence = sequence.pad_sequences(output_vectors_test, maxlen=max_output_length)\n",
    "\n",
    "    X = np.concatenate([question_vectors_sequence, input_vectors_sequence, output_vectors_sequence], axis=1)\n",
    "    scores = model.evaluate(X, labels_test)\n",
    "    \n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question_text, input_spec, output_spec):\n",
    "    question_vectors, input_vectors, output_vectors = vectorize_data([question_text], [input_spec], [output_spec], vocab)\n",
    "    question_vectors_sequence = sequence.pad_sequences(question_vectors, maxlen=max_question_length)\n",
    "    input_vectors_sequence = sequence.pad_sequences(input_vectors, maxlen=max_input_length)\n",
    "    output_vectors_sequence = sequence.pad_sequences(output_vectors, maxlen=max_output_length)\n",
    "    \n",
    "    X = np.concatenate([question_vectors_sequence, input_vectors_sequence, output_vectors_sequence], axis=1)\n",
    "\n",
    "    output_value = model.predict_classes(X)\n",
    "    \n",
    "    output_label = 'Easy' if output_value == 0 else 'Medium' if output_value ==\n",
    "    return output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457/457 [==============================] - 1s 2ms/step\n",
      "Accuracy: 43.98%\n"
     ]
    }
   ],
   "source": [
    "test_model(model, question_vectors_test, input_vectors_test, output_vectors_test, labels_test, max_question_length, max_input_length, max_output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text =\"A group of university students wants to get to the top of a mountain to have a picnic there. For that they decided to use a cableway.A cableway is represented by some cablecars, hanged onto some cable stations by a cable. A cable is scrolled cyclically between the first and the last cable stations (the first of them is located at the bottom of the mountain and the last one is located at the top). As the cable moves, the cablecar attached to it move as well.The number of cablecars is divisible by three and they are painted three colors: red, green and blue, in such manner that after each red cablecar goes a green one, after each green cablecar goes a blue one and after each blue cablecar goes a red one. Each cablecar can transport no more than two people, the cablecars arrive with the periodicity of one minute (i. e. every minute) and it takes exactly 30 minutes for a cablecar to get to the top.All students are divided into three groups: r of them like to ascend only in the red cablecars, g of them prefer only the green ones and b of them prefer only the blue ones. A student never gets on a cablecar painted a color that he doesn't like,The first cablecar to arrive (at the moment of time 0) is painted red. Determine the least time it will take all students to ascend to the mountain top.\"\n",
    "\n",
    "input_spec = \"The first line contains three integers r, g and b (0 ≤ r, g, b ≤ 100). It is guaranteed that r + g + b > 0, it means that the group consists of at least one student.\"\n",
    "\n",
    "output_spec = \"Print a single number — the minimal time the students need for the whole group to ascend to the top of the mountain.\"\n",
    "\n",
    "label = predict(model, question_text, input_spec, output_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
